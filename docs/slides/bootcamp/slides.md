# ğŸ§© Lab Reproducible Workflow Tutorial

_(BIDS â†’ DataLad â†’ Snakemake â†’ Integration & FAIR)_  
Sirota Lab Meeting â€” Progressive, reproducible-workflow bootcamp

---

## Why Reproducible Workflows?

- Increasing complexity of neuroimaging analysis
    
- Challenges: sharing, version drift, reruns
    
- Solution: FAIR + modular workflow
    
    - **BIDS**: structure
        
    - **DataLad**: control
        
    - **Snakemake**: automation
        
    - **Integration**: provenance & sharing
        

---

## A. BIDS â€” Standardized Data Organization

**Goal:** Learn BIDS & immediately apply it.

**Theory**

- Why BIDS; structure & metadata
    
- `sub-*/ses-*`, `dataset_description.json`, sidecars
    

**Practice**

- Convert example dataset to BIDS
    
- Validate with BIDS Validator
    
- Add metadata (`TaskName`, `Manufacturer`, â€¦)
    

Note:  
Talk through motivation; show folder tree; link to validator.

--

### BIDS Folder Skeleton

```text
project/
â””â”€ sub-01/
   â””â”€ anat/
      â”œâ”€ sub-01_T1w.nii.gz
      â””â”€ sub-01_T1w.json
dataset_description.json
```

---

## ğŸ§© Your Turn â€” BIDS

> ğŸ’¡ **Hands-on Practice**

- Download a small sample dataset (or use OpenNeuro example).
    
- Organize it into BIDS format (`sub-01/anat/...`).
    
- Run the [BIDS Validator](https://bids-standard.github.io/bids-validator/).
    
- Fix any filename or metadata issues you encounter.
    

ğŸ• _Take 10 minutes to complete these steps._

---

## B. DataLad â€” Version Control for Data

**Goal:** manage, track, share datasets.

**Concepts**

- Git + git-annex, datasets, subdatasets, RIA, provenance
    

**Practice**

```bash
datalad create my_dataset
echo "hello" > my_dataset/hello.txt
datalad save -m "add hello"
```

Note:  
Explain `datalad create`, `save`, `get`, `push`.

--

### Add as subdataset & push

```bash
datalad create -d . my_dataset
datalad save -m "added dataset"
datalad push --to origin
```

---

## ğŸ§© Your Turn â€” DataLad

> ğŸ’¡ **Hands-on Practice**

- Run `datalad create test_ds`.
    
- Add and save a small file (`echo "test" > file.txt`).
    
- Explore commands:
    
    - `datalad status`
        
    - `datalad get`
        
    - `datalad push`
        
- Inspect `.git/annex` to see how large files are tracked.
    

ğŸ• _5 minutes â€” experiment and share one useful command!_

---

## C. Snakemake â€” Reproducible Pipelines

**Goal:** define & run pipelines on BIDS data.

**Practice**

```python
# Snakefile
rule all:
    input: "derivatives/dummy-png/out.png"

rule calc:
    output: "derivatives/dummy-py/out.txt"
    shell: "python code/calc.py > {output}"

rule plot:
    input: "derivatives/dummy-py/out.txt"
    output: "derivatives/dummy-png/out.png"
    shell: "python code/plot.py {input} {output}"
```

Note:  
Then run `snakemake --cores 2`; show DAG & report.

--

### Visualize & Report

```bash
snakemake --dag | dot -Tpng > dag.png
snakemake --report report.html
```

---

## ğŸ§© Your Turn â€” Snakemake

> ğŸ’¡ **Hands-on Practice**

- Copy or create the sample `Snakefile`.
    
- Run the workflow:
    
    ```bash
    snakemake --cores 2
    ```
    
- Add a new rule that writes todayâ€™s date to a file.
    
- Generate a DAG image and open the `report.html`.
    

ğŸ• _10 minutes â€” make your workflow produce something new!_

---

## D. Integration & FAIR

- Reproducibility â€¢ Adaptability â€¢ Transparency
    
- Package the pipeline; run with provenance
    

```bash
datalad run "snakemake --cores 2"
datalad save -m "run workflow with provenance"
datalad push
```

---

## ğŸ§© Your Turn â€” Integration

> ğŸ’¡ **Hands-on Practice**

- Clone or create a DataLad dataset.
    
- Add your `Snakefile` to the project.
    
- Run your workflow with provenance tracking:
    
    ```bash
    datalad run "snakemake --cores 2"
    ```
    
- View recorded provenance:
    
    ```bash
    datalad run-record show
    ```
    

ğŸ• _5â€“10 minutes â€” confirm your provenance record works._

---

### FAIR Checklist

- **Findable**: DOI / registered repository
    
- **Accessible**: DataLad + open protocols
    
- **Interoperable**: BIDS format
    
- **Reusable**: Metadata + provenance (Snakemake + DataLad)
    

---

âœ… _End of Tutorial â€” Discussion & Q&A_

- What worked smoothly?
    
- What would help you apply this to your own data?
    
- How can we support reproducibility in the labâ€™s shared workflows?
    

---
